{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6283fb76",
   "metadata": {},
   "source": [
    "# üöÄ Build an LLM Chatbot with LangChain + Chroma (Google Colab)\n",
    "This Colab notebook demonstrates how to build a simple chatbot using open-source models and Chroma for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c273f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Install Dependencies ---\n",
    "!pip install langchain chromadb sentence-transformers transformers accelerate bitsandbytes gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Imports ---\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Sample Document ---\n",
    "sample_text = \"\"\"\n",
    "Welcome to the House Expense Manager App.\n",
    "This application allows multiple members in a household to add and track expenses.\n",
    "Each expense has a title, category, payer, participants, and optional receipt image.\n",
    "It can also calculate splits automatically and generate spending statistics.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample.txt\", \"w\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"‚úÖ Loaded {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Create Embeddings & Vector Store ---\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma.from_documents(chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee18436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Load Free/Open LLM ---\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-alpha\"  # Alternative: 'mistralai/Mistral-7B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Query Example ---\n",
    "query = \"How does the app split expenses?\"\n",
    "print(\"‚ùì Query:\", query)\n",
    "print(\"üí¨ Answer:\", qa_chain.run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Optional Gradio Chat Interface ---\n",
    "import gradio as gr\n",
    "\n",
    "def chat_fn(query):\n",
    "    return qa_chain.run(query)\n",
    "\n",
    "iface = gr.Interface(fn=chat_fn, inputs=\"text\", outputs=\"text\", title=\"LangChain + Chroma Chatbot\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
